{"nbformat_minor": 2, "cells": [{"source": "## HDInsight\uc758 \uae30\ubcf8\uba54\ud0c0\uc2a4\ud1a0\uc5b4(Data Lake Storage)\ub85c \ub85c\ub4dc, \ubd84\uc11d, \uc800\uc7a5\ud558\uae30\n- \uc5c4\uccad \ube60\ub974\uae34 \ud568! \u314e\u314e", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "import org.apache.spark.sql.SQLContext", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>3</td><td>application_1534132306360_0007</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-helloc.am5bp12tnuiuda3gjpqeytesrb.ax.internal.cloudapp.net:8088/proxy/application_1534132306360_0007/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn0-helloc.am5bp12tnuiuda3gjpqeytesrb.ax.internal.cloudapp.net:30060/node/containerlogs/container_1534132306360_0007_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\nimport org.apache.spark.sql.SQLContext"}], "metadata": {"collapsed": false}}, {"source": "### adl url\ub85c HVAC.csv\ud30c\uc77c\uc744 file \ubcc0\uc218\uc5d0 \ub85c\ub4dc\ud558\uae30 - RDD\ud615\ud0dc\ub85c \ub85c\ub4dc\uac00 \ub418\ub294 \uac70\uc784", "cell_type": "markdown", "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "val file =  sc.textFile(\"adl:///HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv\")", "outputs": [{"output_type": "stream", "name": "stdout", "text": "file: org.apache.spark.rdd.RDD[String] = adl:///HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv MapPartitionsRDD[1] at textFile at <console>:26"}], "metadata": {"collapsed": false}}, {"source": "### file \ub370\uc774\ud130\uc758 \ub2e8\uc5b4 count\ud558\uae30", "cell_type": "markdown", "metadata": {}}, {"execution_count": 4, "cell_type": "code", "source": "val counts = file.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey(_ + _)\n", "outputs": [{"output_type": "stream", "name": "stdout", "text": "counts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[5] at reduceByKey at <console>:26"}], "metadata": {"collapsed": false}}, {"source": "### counts\uac00 \uc800\uc7a5\ub428", "cell_type": "markdown", "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": "counts.saveAsTextFile(\"adl:///counttest\")", "outputs": [], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}