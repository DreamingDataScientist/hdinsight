{"nbformat_minor": 2, "cells": [{"source": "# Pyspark \uc608\uc81c 1 - wordcount", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "sc", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>7</td><td>application_1534132306360_0011</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-helloc.am5bp12tnuiuda3gjpqeytesrb.ax.internal.cloudapp.net:8088/proxy/application_1534132306360_0011/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn0-helloc.am5bp12tnuiuda3gjpqeytesrb.ax.internal.cloudapp.net:30060/node/containerlogs/container_1534132306360_0011_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n<SparkContext master=yarn appName=remotesparkmagics>"}], "metadata": {"collapsed": false}}, {"execution_count": 2, "cell_type": "code", "source": "word = sc.textFile(\"adl:///study/word_test.txt\")", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 4, "cell_type": "code", "source": "word", "outputs": [{"output_type": "stream", "name": "stdout", "text": "adl:///study/word_test.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"}], "metadata": {"collapsed": false}}, {"execution_count": 6, "cell_type": "code", "source": "word.count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "5"}], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": "word.first()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "u'hello hi who are you'"}], "metadata": {"collapsed": false}}, {"execution_count": 9, "cell_type": "code", "source": "filtered_word = word.filter(lambda word : \"hungry\" in word)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 11, "cell_type": "code", "source": "filtered_word.count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "1"}], "metadata": {"collapsed": false}}, {"execution_count": 13, "cell_type": "code", "source": "filtered_word.collect()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[u'are you hungry? I am hungry so much']"}], "metadata": {"collapsed": false}}, {"execution_count": 14, "cell_type": "code", "source": "words = word.flatMap(lambda word: word.split(\" \"))\ncounts = words.map(lambda word: (word,1)).reduceByKey(lambda a, b : a + b)\nresult = counts.sortBy(lambda c: c[1])", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 16, "cell_type": "code", "source": "result.count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "31"}], "metadata": {"collapsed": false}}, {"execution_count": 17, "cell_type": "code", "source": "result.collect()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(u'do', 1), (u'pyspark', 1), (u'bigdata', 1), (u'thank', 1), (u\"don't\", 1), (u'who', 1), (u'hungry', 1), (u'know', 1), (u'hello', 1), (u'to', 1), (u'much', 1), (u'hahaha', 1), (u'hungry?', 1), (u'hi', 1), (u'eat', 1), (u'hdinsight', 1), (u'lunch?', 1), (u'and', 1), (u'What', 1), (u'java', 1), (u'for', 1), (u'am', 1), (u'python', 1), (u'so', 1), (u'want', 1), (u'apache', 1), (u'spark', 1), (u'minji', 1), (u'I', 2), (u'are', 2), (u'you', 5)]"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}