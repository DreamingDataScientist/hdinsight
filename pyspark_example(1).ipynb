{"nbformat_minor": 2, "cells": [{"source": "# HDInsight \uc0c1\uc758 Pyspark Example (1) - Word Count \uc608\uc81c\n## HDInsight\uc5d0\uc11c\ub294 hadoop \uc124\uce58\ud558\uc9c0 \uc54a\uc544\ub3c4 resource manager\ub294 yarn\uc5d0\uc11c \uc2e4\ud589 \ud568", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "#pip install pandas", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1533704915126_0004</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-sparki.s1rnyv1m0vpe3c04ar5efgrd3e.psx.internal.cloudapp.net:8088/proxy/application_1533704915126_0004/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn3-sparki.s1rnyv1m0vpe3c04ar5efgrd3e.psx.internal.cloudapp.net:30060/node/containerlogs/container_1533704915126_0004_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n"}, {"output_type": "stream", "name": "stderr", "text": "invalid syntax (<stdin>, line 1)\n  File \"<stdin>\", line 1\n    pip install pandas\n              ^\nSyntaxError: invalid syntax\n\n"}], "metadata": {"collapsed": false}}, {"execution_count": 32, "cell_type": "code", "source": "sc", "outputs": [{"output_type": "stream", "name": "stdout", "text": "<SparkContext master=yarn appName=remotesparkmagics>"}], "metadata": {"collapsed": false}}, {"execution_count": 43, "cell_type": "code", "source": "lines = {\n    \"crazy crazy for jumped\",\n    \"hahahaha\",\n    \"Do you want to eat some pizza??\",\n    \"is it possible to be a data architecture?\",\n    \"My awnswer is ..\",\n    \"Why not?\"\n    \"GtPlus means global technology Plus!\"\n}", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 44, "cell_type": "code", "source": "lines_rdd = sc.parallelize(lines)\nlines_rdd", "outputs": [{"output_type": "stream", "name": "stdout", "text": "ParallelCollectionRDD[9] at parallelize at PythonRDD.scala:175"}], "metadata": {"collapsed": false}}, {"execution_count": 45, "cell_type": "code", "source": "frequencies = lines_rdd  \\\n.flatMap(lambda x: x.split(' ')) \\\n.map(lambda x: (x, 1)) \\\n.reduceByKey(lambda x, y: x+y)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 46, "cell_type": "code", "source": "frequencies.collect()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[('global', 1), ('some', 1), ('pizza??', 1), ('crazy', 2), ('data', 1), ('Do', 1), ('to', 2), ('architecture?', 1), ('want', 1), ('not?GtPlus', 1), ('Why', 1), ('hahahaha', 1), ('jumped', 1), ('is', 2), ('you', 1), ('My', 1), ('means', 1), ('technology', 1), ('eat', 1), ('awnswer', 1), ('it', 1), ('Plus!', 1), ('possible', 1), ('be', 1), ('for', 1), ('..', 1), ('a', 1)]"}], "metadata": {"collapsed": false}}, {"execution_count": 47, "cell_type": "code", "source": "frequencies.count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "27"}], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}